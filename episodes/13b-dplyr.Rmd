---
title: Data Frame Manipulation with dplyr
teaching: 30
exercises: 15
source: Rmd
---

::: objectives
-   SUBSET a data set to a smaller, targeted set of rows and/or columns.
-   SORT or RENAME columns.
-   MAKE NEW COLUMNS using old columns as inputs.
-   Generate SUMMARIES of a data set.
-   Use PIPES to string multiple operations on the same data set together into a "paragraph."
:::

::: questions
-   What are the most common types of operations someone might perform on a data frame in R?
-   How can you perform these operations clearly and efficiently?
:::

## Preparation and setup

Note: This set of lessons uses the **gapminder data set**. This data set can be accessed using the following commands:

```{r load gap, eval = T}
install.packages("gapminder") #ONLY RUN THIS COMMAND IF YOU HAVE NOT ALREADY INSTALLED THIS PACKAGE.
library(gapminder) #TURN THE PACKAGE ON
gap = as.data.frame(gapminder) #CREATE A VERSION OF THE DATA SET NAMED gap FOR CONVENIENCE
```

This lesson revolves around the `dplyr` package. `dplyr` is one of the package in the so-called "tidyverse"--an array of packages for R containing extremely useful tools and that are all designed to look similar and work well together. Many of these tools allow you to do operations you can also do in "base R" more efficiently, clearly, or quickly. As such, everything we do in this lesson can be done in "base R" too, but it won't (typically) be as efficient, clear, or fast! As such, the `tidyverse` packages can be viewed as a modern "dialect" of R that many (though not all!) R users use in place of (or in concert with) base R for many tasks.

`dplyr`, like many add-on packages for R, does **not** come pre-installed with R. We can install it using this command:

```{r, eval = FALSE}
install.packages("dplyr") #ONLY RUN THIS COMMAND IF YOU HAVEN'T ALREADY INSTALLED THIS PACKAGE.
```

You only need to install a package once (just like you only need to install a program once), so there's no need to run the above command more than once. [However, packages are updated occasionally. When updates are available, you can re-install new versions using the same `install.packages()` function.]

When you launch R or RStudio, none of the add-on packages you have installed with be "turned on" by default. either So, to turn on `dplyr` so that we can access its features, we use a `library()` call:

```{r, message = FALSE}
library(dplyr) #RUN EACH TIME YOU START UP R AND WANT TO USE THIS PACKAGE'S FEATURES.
```

The above command must be run every time you start up R and want access to `dplyr`'s features.

## Introduction to `dplyr`

R is designed for working with data and data sets. Because data frames (and tibbles, their `tidyverse` equivalents) are the primary object types for holding data sets in R, R users work with data frames (and tibbles) A LOT...like, *a lot a lot*.

When working with data sets stores as data frames (or tibbles), we *very often* find ourselves needing to perform certain actions, such as cutting certain rows or columns out of these objects, renaming columns, or transforming columns into new ones.

We can do ALL of those things in "base R" if we wanted to. In fact, [our "Welcome to R!" lessons](https://umn-dash.github.io/r-novice-gapminder/welcome-to-r.html) demonstrated how to do some of these actions in base R. However, `dplyr` makes doing all these things easier, more concise, AND more intuitive. It does this by adding new verbs (functions) to the R language that all use a consistent syntax and structure (and have intuitive names), allowing us to write code in connected "paragraphs" that do more than commands usually can while also, somehow, being *easier* to read.

In this lesson, we'll go through the most common `dplyr` verbs, showing off their uses.

## SELECT and RENAME

What if we wanted to create a subset of our current data set (a version lacking some rows and/or columns)? When it comes to subsetting by columns, the `dplyr` verb corresponding to this desire is `select()`.

::: callout
**Important**: I said above that one of the strengths of `dplyr` is that all its verbs share a similar structure. Every major `dplyr` verb, including `select()`, takes as its first input the data frame (or tibble) you're trying to manipulate.

After that first input, every *subsequent* input you provide becomes another "thing" you want the function to do to that data frame.
:::

What I mean by that last part will become clearer via an example. Suppose I want a new, smaller version of the `gapminder` data set that is *only* the `country` and `year` columns from the original. I could use `select()` to achieve that desire like this:

```{r}
gap_shrunk = select(gap, #1ST INPUT IS ALWAYS THE DATA FRAME TO BE MANIPULATED
               country, year) #EACH SUBSEQUENT INPUT IS "ANOTHER THING TO DO" TO THAT DATA FRAME. HERE, IT'S THE COLUMNS WE WANT TO KEEP IN OUR SUBSET.
head(gap_shrunk)
```

In the example above, I provided my data frame as the first input to `select()` and then all the columns I wanted to *select* as subsequent inputs. As a result, I ended up with a shrunken version of the original data set, one containing only those two columns.

::: callout
Notice that, in the `tidyverse` packages, column names are often **unquoted** when used as inputs.
:::

[In our subsetting and indexing lesson](https://umn-dash.github.io/r-novice-gapminder/welcome-to-r.html#subsetting-and-indexing), we learned some "tricks" for subsetting objects in R. Many of those tricks with `select()` too. For example, you can select a sequence of consecutive columns by using the `:` operator and the names of the first and last columns in that sequence:

```{r}
gap_sequence = select(gap, 
                      pop:lifeExp) #SELECT ALL COLUMNS FROM pop TO lifeExp
head(gap_sequence)
```

We can also use the `-` operator to specify columns we want to *reject* instead of keep. For example, to retain every column *except* `year`, we could do this:

```{r}
gap_noyear = select(gap, 
                    -year) #EXCLUDE YEAR FROM THE SUBSET
head(gap_noyear)
```

We can also use `select()` to *rearrange* columns by specifying the column names in the new order we want them in:

```{r}
gap_reordered = select(gap, 
                       year, country) #THE ORDER HERE SPECIFIES THE ORDER IN THE SUBSET
head(gap_reordered)
```

### Renaming

What if wanted to rename some of our columns? The `dplyr` verb corresponding to this desire is, fittingly, `rename()`.

As with `select()` (and *all* `dplyr` verbs!), `rename()`'s first input is the data frame we're manipulating. Each subsequent input is an "instructions list" for how to do that renaming, with the new name to give to a column to the left of an `=` operator and the old name of that column to the right of it (what I like to call **new = old format**).

For example, to rename the `pop` column to "population," which I would *personally* find to be more informative, we would do the following:

```{r}
gap_renamed = rename(gap, 
                     population = pop) #NEW = OLD FORMAT TO RENAME COLUMNS
head(gap_renamed)
```

It's as simple as that! If we wanted to rename multiple columns at once, we could add more inputs to the same `rename()` call.

## Magical pipes

::: challenge
What if I wanted to *first* eliminate some columns and *then* rename some of the remaining columns? How would you accomplish that goal, based on what I've taught you so far?

::: solution
Your *first* impulse might be to do this in two commands, saving **intermediate objects** at each step, like so:

```{r}
gap_selected = select(gap, 
                      country:pop) #FIRST, CREATE OUR SUBSET, AND SAVE AN INTERMEDIATE OBJECT CALLED gap_selected.

gap_remonikered = rename(gap_selected, 
               population = pop) #USE THAT OBJECT IN THE RENAMING COMMAND.

head(gap_remonikered)
```
:::
:::

There's **nothing** *wrong* with this approach, but it's...tedious. Plus, if you don't pick *really* good names for each intermediate object, it can get confusing for you and others to read.

I hope you're thinking "I bet there's a better way." And there is! We can combine these two discrete "sentences" into one, easy-to-read "paragraph." The only catch is we have to use a strange operator called a **pipe** to do it.

`dplyr` pipes look like this: `%>%`. On Windows, the hotkey to render a pipe is Control + shift + m! On Mac, it's similar: Command + shift + m.

::: callout
Pipes may look a *little* funny, but they do something *really* cool. They take the "thing" produced on their left (once all operations over there are complete) and "pump" that thing into the operations on their right automatically, *specifically into the first available input slot*.
:::

This is easier to explain with an example, so let's see how to use pipes to perform the two operations we did above in a single command:

```{r}
gap.final = gap %>% #START WITH OUR RAW DATA SET, THEN PIPE IT INTO...
  select(country:pop) %>% #OUR SELECT CALL, THEN PIPE THE RESULT INTO...
  rename(population = pop) #OUR RENAME CALL. PIPES ALWAYS PLACE THEIR "BURDENS" IN THE FIRST AVAILABLE INPUT SLOT, WHICH IS WHERE dplyr VERBS EXPECT THE DATA FRAME TO GO ANYWAY!
head(gap.final)
```

The command above says: "Take the raw `gapminder` data set and pump it into `select()`'s first input slot (where it belongs anyway). Then, do `select()`'s operations (which yield a new, subsetted data set) and pump *that* into `rename()`'s first input slot. Then, when that function is done, save the result into an object called `gap.final`."

Hopefully, you can see how "`dplyr` paragraphs" like this one could be easier to read and follow along with but more code-efficient too! The existence of pipes also explains why every `dplyr` verb's first input slot is the data frame to be manipulated—it makes every verb ready to receive "upstream" inputs via a pipe!

Pipes are so useful to writing clean, efficient `tidyverse` code that few `tidyverse` users eschew them. So, we'll be using them for the rest of this lesson and the ones beyond, so you'll get plenty of practice with them!

## FILTER, ARRANGE, and MUTATE

What if we only wanted to look at data from a specific continent or a specific time frame (*i.e.*, we wanted to subset by rows instead)? The `dplyr` verb corresponding to this desire is `filter()` (see, I said `dplyr` verbs have intuitive names!).

Each input given to `filter()` past the first (which is ALWAYS the data frame to be manipulated, as we've established!) is [a **logical test**, a construction we've seen before](https://umn-dash.github.io/r-novice-gapminder/welcome-to-r.html#logical-tests). Each **logical test**here willconsist of the name of the column we'll check the values of, a **logical operator** (like `==` for "is equal to" or `<=` for "is less than or equal to"), and a "threshold" to check the values in that column against.

If *all* the logical tests pass for a particular row, we keep that row. Otherwise, we remove that row from the new, subsetted data frame we create.

For example, here's how we'd filter our data set to just rows where the value in the `continent` column is *exactly* `"Europe"`:

```{r}
gap_europe = gap %>% 
  filter(continent == "Europe") #THE COLUMN TO CHECK VALUES IN, AN OPERATOR, THEN THE THRESHOLD VALUE TO CHECK THEM AGAINST. 

head(gap_europe)
```

As another example, here's how we'd filter our data set to just rows with data from before the year `1975`:

```{r}
gap_pre1975 = gap %>% 
  filter(year < 1975)

head(gap_pre1975)
```

::: challenge
What if we wanted data only from *between* the years 1970 and 1979? How would you achieve this goal using `filter()`? Hint: There are *at least* three valid ways you should be able to think of to do this!

::: solution
The first solution is to use `&` (R's "AND" operator) to specify two rules a value in the `year` column must satisfy to pass:

```{r}
and_option = gap %>% 
  filter(year > 1969 & 
           year < 1980) #YOU COULD USE LESS THAN OR EQUAL TO OPERATORS HERE ALSO, BUT DIFFERENT YEAR VALUES WOULD BE NEEDED.
```

However, I said earlier that every input to `filter()` past the first is another **logical test** a row *must* satisfy to pass. So, just specifying two **logical tests**here, with a comma in between, has the same effect:

```{r}
comma_option = gap %>% 
  filter(year > 1969, 
         year < 1980)
```

Of course, if you prefer, you can use multiple `filter()` calls back to back, each containing just one rule:

```{r}
stacked_option = gap %>% 
  filter(year > 1969) %>% 
  filter(year < 1980)
```

None of these approaches is "right" or "wrong," so you can decide which ones you prefer!
:::
:::

::: challenge
**Important**: When chaining `dplyr` verbs together in "paragraphs" via **pipes**, order matters! Why does the following code trigger an **error** when executed?

```{r, eval = FALSE}
this_will_fail = gap %>% 
  select(pop:lifeExp) %>% 
  filter(year < 1975)
```

::: solution
Recall that the `year` column is *not* one of the columns between the `pop` and `lifeExp` columns. So, the `year` column gets cuts by the `select()` call here *before* we get to the `filter()` call that tries to use it as an input, so the `filter()` call fails to find that column.

Considering that `dplyr` "paragraphs" can get long and complicated, remember to be thoughtful about the order you specify actions in!
:::
:::

### Sorting

What if we wanted to *sort* our data set by the values in one (or more) columns? The `dplyr` verb corresponding to this desire is `arrange()`.

Every input past the first given to `arrange()` is a column we want to sort by, with earlier columns taking "precedence" over later ones.

For example, here's how we'd sort our data set by the `lifeExp` column (in *ascending* order):

```{r}
gap_sorted = gap %>% 
  arrange(lifeExp)

head(gap_sorted)
```

Ascending order is the default for `arrange()`. If we want to reverse it, we use the `desc()` helper function:

```{r}
gap_sorted_down = gap %>% 
  arrange(desc(lifeExp)) #DESCENDING ORDER INSTEAD.

head(gap_sorted_down)
```

::: challenge
I mentioned above that you can provide multiple inputs to `arrange()`, but it's a *little* hard to explain what this does, so let's try it and see what happens:

```{r}
gap_2xsorted = gap %>% 
  arrange(year, continent)

head(gap_2xsorted)
```

What did this command do? Why? What would change if you reversed the order of `continent` and `year` in the call?

::: solution
This command *first* sorted the data set by the unique values in the `year` column. It then "broke any ties," in which 2+ rows have the *same* `year` value, by *then* sorting by the `continent` column's values within each of those tied groups.

So, we get records for `Africa` sooner than we get records for `Asia` for the same year, but records from `Africa` and `Asia` alternate as we go through all the years. If we reversed the order of our two inputs, we'd instead get *all* records for `Africa`, in chronological order by `year`, before getting *any* records for `Asia`.

This mirrors the behavior of "multi-column sorting" as it exists in programs like Microsoft Excel.
:::
:::

### Generating new columns

What if we wanted to make a new column using an old column's values as inputs? This is the kind of thing many of us are used to doing in Microsoft Excel, where it isn't always easy or reproducible. Thankfully, we have the `dplyr` verb `mutate()` to match with this desire.

Every input to `mutate()` past the first is an "instructions list" for how to make a new column using one or more old columns as inputs, and these follow **new = old format** again.

For example, here's how we would create a new column called `pop1K` that is made by dividing the `pop` column's values by 1000:

```{r}
gap_newcol = gap %>% 
  mutate(pop1K = round(pop / 1000)) #NEW = OLD FORMAT. WHAT WILL THE NEW COLUMN BE CALLED, AND HOW SHOULD WE OPERATE ON THE OLD COLUMN TO MAKE IT?

head(gap_newcol)
```

You'll note that the old `pop` column still exists after this command. If you want to get rid of it, now that you've used it, you can specify the input `.keep = "unused"` to `mutate()` and it will eliminate any columns used to create new ones. Try it!

## GROUP_BY and SUMMARIZE

One the most powerful actions we might want to take on a data set is to generate a **summary**. "What's the mean of *this* column?" or "What's the median value for all the different groups in *that* column?", for example.

Suppose we wanted to calculate the mean life expectancy across all years for each country. We *could* use `filter()` to go country by country, save each subset as an **intermediate object**, and then take a mean of each subset's `lifeExp` column. It'd work, but what a *pain* it'd be!

Thankfully, we don't have to; instead, we can use the `dplyr` verbs `group_by()` and `summarize()`! Unlike other `dplyr` verbs we've met so far, these are a duo—they're *generally* used together and, importantly, we *always* use `group_by()` first when we do use them as a pair.

So, let's start by understanding what `group_by()` does. Each input given to `group_by()` past the first creates groupings in the data. Specifically, you provide a column name, and R will find all the different values in that column (such as all the different unique country names) and subtly "bundle up" all the rows that possess each different value.

...This is easier to show you than to explain, so let's try it:

```{r}
gap_grouped = gap %>% 
  group_by(country) #FIND EACH UNIQUE COUNTRY AND BUNDLE ROWS FROM THE SAME COUNTRY TOGETHER.

head(gap_grouped)
```

When we look at the new data set, it will *look* as though nothing has changed. And, in a lot of ways, nothing has! However, if you examine `gap_grouped` in your RStudio's 'Environment' Pane, you'll notice that `gap_grouped` is considered a "grouped data frame" instead of a plain-old one.

We can see what that means by using the `str()` ("structure") function to peek "under the hood" at `gap_grouped`:

```{r}
str(gap_grouped)
```

If we look towards the bottom of this output, we'll see that, for every unique value in the `country` column, there is now a list of all the *row numbers* of rows sharing that country value (*i.e.*, all the rows for `"Afghanistan"`, all the rows for `"Albania"`, *etc.*).

In other words, R now knows that each row belongs to one specific group within the larger data set. So, when we *then* ask it to calculate a **summary**, it can do so for each group separately.

Let's see how that works by next examining `summarize()`. Each input past the first given to `summarize()` is an "instructions list" for how to generate a summary, with these "instructions lists" once again taking **new = old format** (see, I said these tools were designed to be consistent!).

For example, let's tell `summarize()` to calculate a mean life expectancy for every country and to call the new column holding those summary values `mean_lifeExp`:

```{r}
gap_summarized = gap_grouped %>%  #USE THE GROUPED DATA FRAME AS THE INPUT HERE!
  summarize(mean_lifeExp = mean(lifeExp)) #USE THE OLD COLUMN TO CALCULATE MEANS, THEN NAME THE RESULT mean_lifeExp. THE MEANS WILL BE CALCULATED SEPARATE FOR EACH GROUP BECAUSE WE HAVE A GROUPED DATA FRAME.

head(gap_summarized)
```

::: challenge
Consider: How many rows does `gap_summarized` have? Why does it have so many fewer rows than `gap_grouped` did? Where did all the other columns go?

::: solution
`gap_summarized` only has 142 rows, whereas `gap_grouped` had 1,704. The reason for this is that we summarized our data *by group*; we asked R to give us a *single value* (a mean) for each group in our data set. There are only 142 countries in the `gapminder` data set, so we end up with a single row for each country.

But where did all the other columns go? Well, we didn't ask for summaries of those other columns too. So, if there used to be 12 values of `pop` for a given country *before* summarization, but there's going to be just a single row for a given country *after* summarization, and we don't tell R how to "collapse" those 12 values down to just one, it's more "responsible" for R to just drop those columns entirely rather than guess how it should do that collapsing. That's the logic, anyway!
:::
:::

If you want to generate multiple summaries, you can provide multiple inputs to `summarize()`. For example, `n()` is a handy function for counting up the number of data points in each group prior to any summarization:

```{r}
gap_summarized = gap_grouped %>%  
  summarize(mean_lifeExp = mean(lifeExp),
            sample_sizes = n()) 

head(gap_summarized)
```

Here, all the values in our new `sample_sizes` column are `12` because we have exactly 12 records per country to start with, but if the numbers of records differed between countries, the above operation would have shown us that.

::: challenge
One more concept: You can provide multiple inputs to `group_by()`, just as with any other `dplyr` verb. What happens when we do? Let's try it:

```{r}
gap_2xgrouped = gap %>% 
  group_by(continent, year)

str(gap_2xgrouped)
```

How did R group together rows in this case?

Next, try generating mean life expectancies and sample sizes using `gap_2xgrouped` as an input. You'll get different values than we did before, and we'll also get a different number of rows in the resulting output. Why?

::: solution
First, here's the code we'd to write to generate the summaries described above:

```{r, message= FALSE}
gap_2xsummarized = gap_2xgrouped %>%  
  summarize(mean_lifeExp = mean(lifeExp),
            sample_sizes = n()) 

head(gap_2xsummarized)
```

By specifying multiple columns to group by, what R did is find the rows belonging to each unique *combination* of the values across the two columns we specified. That is, here, it found the rows that belong to each unique `continent` x `year` combo and made those a group.

So, when we then summarized that grouped data frame, R calculated summaries for each unique `continent` and `year` combo. Because there are differing numbers of countries in each `continent`, our sample sizes now differ.
:::
:::

::: keypoints
-   Use the `dplyr` package to manipulate data frames in efficient, clear, and intuitive ways.
-   Use `select()` to retain specific columns when creating subsetted data frames.
-   Use `filter()` to create a subset by rows using logical tests to determine whether a row should be kept or gotten rid of.
-   Use `group_by()` and `summarize()` to generate summaries of categorical groups within a data set.
-   Use `mutate()` to create new variables using old ones as inputs.
-   Use `rename()` to rename columns.
-   Use `arrange()` to sort your data set by one or more columns.
-   Use pipes (`%>%`) to string `dplyr` verbs together into "paragraphs."
-   Remember that order matters when stringing together `dplyr` verbs!
:::
